<a href="#register">Register</a> | <a href="#program">Program</a> | <a href="#logistics">Logistics</a>
<img src="DIRI_LOGO.jpg" alt="DIRI" height="50" align="right"><img src="ONS_RGB_Billingual.jpg" alt="ONS" height="50" align="right"> 
# (Differentially) Private Synthetic Data Workshop 
Cardiff University, December 11th 2019, Bute Building S/2.32


## Call
We live in a society that is collecting data at an unprecedented level and very often this data is sensitive. Scientific studies often use confidential data. Government agencies hold data about citizens that are equally sensitive. And companies - think Facebook, Google or Twitter - are amassing data about consumer (online) behavior.

The original microdata can usually not be shared due to privacy concerns. Yet access for researchers to such data could potentially lead to new discoveries.  Statistical agencies might even be obliged to publish data without harming the privacy of individuals in the original collection.

One idea that recent research has increasingly focussed on is generating synthetic data. Ideally, synthetic microdata allows researchers to draw similar inferences as with the original data while protecting privacy. First promising research on synthesising microdata under strict privacy definitions - e.g. under differential privacy - has been published.

However, the debates often remain within their respective academic disciplines. This workshop intends to bring together leading researchers on privacy preserving synthetic data from computer sciences, statistics and applied backgrounds such as social sciences. Spotlighting recent advances in the respective disciplines, we especially seek to facilitate an interdisciplinary debate. Our goal is to share best practices and insights, identify joint challenges, and sketch the foundation for a joint roadmap.

Open questions include:
- How to measure disclosure risk with synthetic data?
- How to measure the utility of synthetic data for yet unknown analyses?
- How to account for the errors introduced by the privacy protection mechanism in subsequent analyses?
- What is an intuitive measure of privacy protection for applied researchers?

## Register
If you want to participate, please get in contact with [Chris Arnold](https://www.cardiff.ac.uk/people/view/994654-arnold-christian)

## Logistics
* Registration is open from 9am.
* The workshop starts at 10am and ends at 6pm.
* Every presentation can take up to 20mins.
* Each block consists of a set of presentations and 30mins joint discussions/questions.
* After each block, there is a 30mins break to chat, have coffee/tea and a sandwich in an informal setting.
* The last hour is an open space format to enable further collaborations.
* For those who want to continue, we will have dinner at [Valentino's](https://www.valentinocardiff.com/) at 7pm. Please confirm your participation with [Chris](mailto:arnoldc6@cardiff.ac.uk) until December 4th.
* We will provide you with a quick 4 item questionnaire after the workshop. Chris and George will use it to collect joint learnings, edit responses and feed everything back to you.


## Program

### 1 Private Synthetic Data in Practice (10am&mdash;12am)


#### Synthetic Data As a Regulatory Enabler
*Pavle Avramovic (Financial Conduct Authority)*

#### Increasing Access to Data While Maintaining Trust
*Fionntán O'Donnell (Open Data Institute)*

#### Towards a Future Where Privacy Enables Innovation
*Pierre-Andre Maugis (Privitar)*

#### Synthetic Data in the Office for National Statistics: Research, Challenges and Applications
*Ioannis Kaloskampis (Office for National Statistics)*

### 2 Working With Differentially Private Information (12.30pm&mdash;2.15pm)

#### Differential Privacy for Government Agencies&mdash;Some Things to Consider
*Jörg Drechsler (Institute for Employment Research, Germany)*

#### Really Useful Synthetic Data&mdash;Promises and Challenges of Releasing Sensitive Information With Differentially Private Data Synthesizers
*Christian Arnold (Cardiff University), Marcel Neunhoeffer (University of Mannheim) and Sebastian Sternberg (University of Mannheim)*

#### Is It Safe to Leave &epsilon;-Differentially Private Data On A Train?
*Gillian Raab (University of Edinburgh)*

### 3 New Ways of Advancing Data Privacy and Utility (2.45pm&mdash;5pm)

#### Protecting String Data from Reconstruction and Confidential Knowledge Exposure
*Grigorios Loukides (Kings College London)*

#### The Trade-off between Information Utility and Disclosure Risk in a GA Synthetic Data Generator
*Mark Elliot (University of Manchester)*

#### Integrating Differential Privacy in the Statistical Disclosure Control Tool-kit for Synthetic Data Production
*Natalie Shlomo (University of Manchester)*

#### Multiplicative Weights Post-Amplification of Differentially Private GANs
*Cynthia Dwork (Microsoft Research), Marcel Neunhoeffer (University of Mannheim) and Zhiwei Steven Wu (University of Minnesota)*

#### Differentially Private Mixture of Generative Neural Networks
*Emiliano De Cristofaro (University College London)*


### 4 Joint Discussion: Further Pathways (5.15pm&mdash;6pm)

#### Report from the Protecting Citizens Online Funding Workshop, UKRI
*George Theodorakopoulos (Cardiff University)*

#### Open Space




## Organising Team 
- Christian Arnold (Cardiff University)
- Marcel Neunhoeffer (University of Mannheim)
- George Theodorakopoulos (Cardiff University)
